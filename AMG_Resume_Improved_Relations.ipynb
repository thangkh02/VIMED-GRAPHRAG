{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === RESUME EXTRACTION V·ªöI IMPROVED RELATION PROMPTS ===\n",
                "!pip install -q langchain-groq pyvis pypdf networkx pydantic python-dotenv\n",
                "\n",
                "import os\n",
                "import re\n",
                "import time\n",
                "import pickle\n",
                "import unicodedata\n",
                "import networkx as nx\n",
                "from typing import List\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "from langchain_text_splitters import TokenTextSplitter\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_groq import ChatGroq\n",
                "from pyvis.network import Network\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "print(\"‚úÖ Import OK\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === C·∫§U H√åNH ===\n",
                "load_dotenv()\n",
                "\n",
                "GROQ_API_KEYS = [\n",
                "    os.getenv(\"GROQ_API_KEY_1\"), os.getenv(\"GROQ_API_KEY_2\"),\n",
                "    os.getenv(\"GROQ_API_KEY_3\"), os.getenv(\"GROQ_API_KEY_4\"),\n",
                "    os.getenv(\"GROQ_API_KEY_5\"), os.getenv(\"GROQ_API_KEY_6\"),\n",
                "    os.getenv(\"GROQ_API_KEY_7\"), os.getenv(\"GROQ_API_KEY_8\"),\n",
                "    os.getenv(\"GROQ_API_KEY_9\"),\n",
                "]\n",
                "PDF_PATH = os.getenv(\"PDF_PATH\")\n",
                "\n",
                "# Normalize\n",
                "MEDICAL_ABBREVIATIONS = {\n",
                "    \"btm\": \"b·ªánh th·∫≠n m·∫°n\", \"tha\": \"tƒÉng huy·∫øt √°p\", \"ƒëtƒë\": \"ƒë√°i th√°o ƒë∆∞·ªùng\",\n",
                "    \"gfr\": \"ƒë·ªô l·ªçc c·∫ßu th·∫≠n\", \"ckd\": \"b·ªánh th·∫≠n m·∫°n\",\n",
                "}\n",
                "\n",
                "MEDICAL_SYNONYMS = {\n",
                "    \"b·ªánh th·∫≠n m·∫°n\": [\"b·ªánh th·∫≠n m√£n\", \"suy th·∫≠n m·∫°n\", \"ckd\"],\n",
                "    \"ƒë√°i th√°o ƒë∆∞·ªùng\": [\"ti·ªÉu ƒë∆∞·ªùng\", \"ƒëtƒë\", \"diabetes\"],\n",
                "}\n",
                "\n",
                "def normalize_medical_text(text: str) -> str:\n",
                "    if not text: return \"Unknown\"\n",
                "    text = unicodedata.normalize(\"NFC\", text).strip().lower()\n",
                "    text = re.sub(r'\\s+', ' ', text)\n",
                "    words = [MEDICAL_ABBREVIATIONS.get(re.sub(r'[^\\w]', '', w), w) for w in text.split()]\n",
                "    text = ' '.join(words)\n",
                "    for canonical, variants in MEDICAL_SYNONYMS.items():\n",
                "        for variant in variants:\n",
                "            text = text.replace(variant, canonical)\n",
                "    return re.sub(r'\\s+', ' ', text).strip().title()\n",
                "\n",
                "class APIKeyManager:\n",
                "    def __init__(self, api_keys: List[str]):\n",
                "        self.api_keys = [k for k in api_keys if k]\n",
                "        self.current_index = 0\n",
                "        self.failed_keys = set()\n",
                "    def get_current_key(self) -> str:\n",
                "        return self.api_keys[self.current_index]\n",
                "    def rotate_key(self) -> bool:\n",
                "        self.failed_keys.add(self.current_index)\n",
                "        for i in range(len(self.api_keys)):\n",
                "            next_idx = (self.current_index + 1 + i) % len(self.api_keys)\n",
                "            if next_idx not in self.failed_keys:\n",
                "                self.current_index = next_idx\n",
                "                print(f\"üîÑ Key #{next_idx + 1}\")\n",
                "                return True\n",
                "        return False\n",
                "    def reset_failed(self):\n",
                "        self.failed_keys.clear()\n",
                "\n",
                "api_manager = APIKeyManager(GROQ_API_KEYS)\n",
                "print(f\"‚úÖ {len(api_manager.api_keys)} API keys\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SCHEMA ===\n",
                "class MedicalEntity(BaseModel):\n",
                "    name: str\n",
                "    type: str\n",
                "    description: str = \"\"\n",
                "    relevance_score: int = Field(default=5, ge=1, le=10)\n",
                "\n",
                "class MedicalRelation(BaseModel):\n",
                "    source_name: str\n",
                "    target_name: str\n",
                "    relation: str\n",
                "    confidence_score: int = Field(default=5, ge=1, le=10)\n",
                "    evidence: str = \"\"\n",
                "\n",
                "class AMGExtractionResult(BaseModel):\n",
                "    entities: List[MedicalEntity] = Field(default_factory=list)\n",
                "    relations: List[MedicalRelation] = Field(default_factory=list)\n",
                "\n",
                "print(\"‚úÖ Schema OK\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOAD CHECKPOINT ===\n",
                "graph_path = \"./amg_data/graph_full.pkl\"\n",
                "\n",
                "if os.path.exists(graph_path):\n",
                "    with open(graph_path, \"rb\") as f:\n",
                "        G = pickle.load(f)\n",
                "    print(f\"‚úÖ Loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è T·∫°o graph m·ªõi\")\n",
                "    G = nx.DiGraph()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === ‚òÖ IMPROVED EXTRACTOR V·ªöI RELATION FOCUS ===\n",
                "class ImprovedAMGExtractor:\n",
                "    def __init__(self, api_manager: APIKeyManager):\n",
                "        self.api_manager = api_manager\n",
                "        \n",
                "        # ‚òÖ‚òÖ‚òÖ PROMPT C·∫¢I TI·∫æN - FOCUS V√ÄO RELATIONS ‚òÖ‚òÖ‚òÖ\n",
                "        self.extraction_prompt = ChatPromptTemplate.from_messages([\n",
                "            (\"system\", \"\"\"B·∫°n l√† chuy√™n gia tr√≠ch xu·∫•t th·ª±c th·ªÉ v√† QUAN H·ªÜ y t·∫ø.\n",
                "\n",
                "## ENTITY TYPES:\n",
                "DISEASE, DRUG, SYMPTOM, TEST, ANATOMY, TREATMENT, PROCEDURE, RISK_FACTOR, LAB_VALUE\n",
                "\n",
                "## RELATION TYPES (QUAN TR·ªåNG):\n",
                "CAUSES, TREATS, DIAGNOSED_BY, ASSOCIATED_WITH, RISK_FOR, INDICATES, CONTRAINDICATED_FOR, ADMINISTERED_FOR, MONITORS\n",
                "\n",
                "## SCORING:\n",
                "**Entities:** 9-10 (ch√≠nh), 7-8 (quan tr·ªçng), 5-6 (ph·ª•)\n",
                "**Relations:** 9-10 (ch·∫Øc ch·∫Øn), 7-8 (c√≥ b·∫±ng ch·ª©ng r√µ), 5-6 (c√≥ li√™n quan)\n",
                "\n",
                "## ‚òÖ FEW-SHOT EXAMPLES (C√ì RELATIONS):\n",
                "\n",
                "**Example 1:**\n",
                "Input: \"B·ªánh th·∫≠n m·∫°n giai ƒëo·∫°n 5 c·∫ßn l·ªçc m√°u. ƒêi·ªÅu tr·ªã b·∫±ng erythropoietin khi Hb < 10g/dL.\"\n",
                "\n",
                "Entities:\n",
                "- B·ªánh th·∫≠n m·∫°n giai ƒëo·∫°n 5 (DISEASE, score=10)\n",
                "- L·ªçc m√°u (TREATMENT, score=9)\n",
                "- Erythropoietin (DRUG, score=8)\n",
                "- Hb < 10g/dL (LAB_VALUE, score=7)\n",
                "\n",
                "Relations:\n",
                "- B·ªánh th·∫≠n m·∫°n giai ƒëo·∫°n 5 ‚Üí TREATED_BY ‚Üí L·ªçc m√°u (conf=10, evidence: \"c·∫ßn l·ªçc m√°u\")\n",
                "- Hb < 10g/dL ‚Üí INDICATES ‚Üí Thi·∫øu m√°u (conf=9)\n",
                "- Erythropoietin ‚Üí ADMINISTERED_FOR ‚Üí Thi·∫øu m√°u (conf=9, evidence: \"khi Hb < 10g/dL\")\n",
                "- B·ªánh th·∫≠n m·∫°n ‚Üí CAUSES ‚Üí Thi·∫øu m√°u (conf=8)\n",
                "\n",
                "**Example 2:**\n",
                "Input: \"ƒê√°i th√°o ƒë∆∞·ªùng type 2 l√† y·∫øu t·ªë nguy c∆° h√†ng ƒë·∫ßu g√¢y b·ªánh th·∫≠n m·∫°n. Ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt b·∫±ng metformin.\"\n",
                "\n",
                "Entities:\n",
                "- ƒê√°i th√°o ƒë∆∞·ªùng type 2 (DISEASE, score=10)\n",
                "- B·ªánh th·∫≠n m·∫°n (DISEASE, score=10)\n",
                "- Metformin (DRUG, score=8)\n",
                "- Ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt (TREATMENT, score=8)\n",
                "\n",
                "Relations:\n",
                "- ƒê√°i th√°o ƒë∆∞·ªùng type 2 ‚Üí RISK_FOR ‚Üí B·ªánh th·∫≠n m·∫°n (conf=10, evidence: \"y·∫øu t·ªë nguy c∆° h√†ng ƒë·∫ßu\")\n",
                "- ƒê√°i th√°o ƒë∆∞·ªùng type 2 ‚Üí CAUSES ‚Üí B·ªánh th·∫≠n m·∫°n (conf=9)\n",
                "- Metformin ‚Üí TREATS ‚Üí ƒê√°i th√°o ƒë∆∞·ªùng type 2 (conf=9, evidence: \"ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt\")\n",
                "- Ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt ‚Üí TREATS ‚Üí ƒê√°i th√°o ƒë∆∞·ªùng type 2 (conf=9)\n",
                "\n",
                "## ‚òÖ QUY T·∫ÆC QUAN TR·ªåNG:\n",
                "1. **PH·∫¢I T√åM T·ªêI THI·ªÇU 3-5 RELATIONS cho m·ªói ƒëo·∫°n vƒÉn**\n",
                "2. T√¨m c·∫£ quan h·ªá TR·ª∞C TI·∫æP v√† GI√ÅN TI·∫æP\n",
                "3. Evidence ph·∫£i tr√≠ch d·∫´n ch√≠nh x√°c t·ª´ vƒÉn b·∫£n\n",
                "4. Confidence cao n·∫øu c√≥ t·ª´ kh√≥a r√µ r√†ng: \"g√¢y\", \"ƒëi·ªÅu tr·ªã\", \"ch·∫©n ƒëo√°n\", \"li√™n quan\"\n",
                "5. GI·ªÆ NGUY√äN ti·∫øng Vi·ªát, KH√îNG extract: quy·∫øt ƒë·ªãnh, vƒÉn b·∫£n, s·ªë trang\n",
                "\n",
                "Tr√≠ch xu·∫•t ENTITIES v√† NHI·ªÄU RELATIONS:\"\"\"),\n",
                "            (\"human\", \"{text}\")\n",
                "        ])\n",
                "        \n",
                "        self._init_llm()\n",
                "    \n",
                "    def _init_llm(self):\n",
                "        self.llm = ChatGroq(temperature=0.1, model=\"llama-3.3-70b-versatile\", \n",
                "                           api_key=self.api_manager.get_current_key())\n",
                "        self.chain = self.extraction_prompt | self.llm.with_structured_output(AMGExtractionResult)\n",
                "    \n",
                "    def extract(self, text: str, max_retries=3):\n",
                "        for attempt in range(max_retries):\n",
                "            try:\n",
                "                result = self.chain.invoke({\"text\": text})\n",
                "                if result:\n",
                "                    # Filter\n",
                "                    valid = [e for e in result.entities \n",
                "                            if len(e.name) >= 2 and \n",
                "                            not any(x in e.name.lower() for x in ['quy·∫øt ƒë·ªãnh', 'vƒÉn b·∫£n', 'trang'])]\n",
                "                    result.entities = valid\n",
                "                return result if result else AMGExtractionResult()\n",
                "            except Exception as e:\n",
                "                if \"rate\" in str(e).lower() or \"limit\" in str(e).lower():\n",
                "                    if self.api_manager.rotate_key():\n",
                "                        self._init_llm()\n",
                "                        time.sleep(2)\n",
                "                    else:\n",
                "                        print(\"‚è≥ Ch·ªù 5 ph√∫t...\")\n",
                "                        time.sleep(300)\n",
                "                        self.api_manager.reset_failed()\n",
                "                        self._init_llm()\n",
                "                else:\n",
                "                    time.sleep(1)\n",
                "        return AMGExtractionResult()\n",
                "\n",
                "print(\"‚úÖ Improved Extractor ready (RELATION FOCUS)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === HELPERS ===\n",
                "def add_entity(G, entity: MedicalEntity, page_num: int):\n",
                "    norm_name = normalize_medical_text(entity.name)\n",
                "    confidence = min(1.0, entity.relevance_score / 10.0)\n",
                "    \n",
                "    if not G.has_node(norm_name):\n",
                "        G.add_node(norm_name, label=entity.name, type=entity.type.upper(),\n",
                "                  description=entity.description, confidence=confidence,\n",
                "                  relevance_score=entity.relevance_score, pages=[page_num])\n",
                "    else:\n",
                "        old_conf = G.nodes[norm_name].get('confidence', 0)\n",
                "        if confidence > old_conf:\n",
                "            G.nodes[norm_name]['confidence'] = confidence\n",
                "        if page_num not in G.nodes[norm_name]['pages']:\n",
                "            G.nodes[norm_name]['pages'].append(page_num)\n",
                "\n",
                "def add_relation(G, rel: MedicalRelation, page_num: int):\n",
                "    src = normalize_medical_text(rel.source_name)\n",
                "    tgt = normalize_medical_text(rel.target_name)\n",
                "    if G.has_node(src) and G.has_node(tgt):\n",
                "        G.add_edge(src, tgt, relation=rel.relation.upper(),\n",
                "                  confidence=min(1.0, rel.confidence_score/10), \n",
                "                  evidence=rel.evidence, page=page_num)\n",
                "\n",
                "print(\"‚úÖ Helpers OK\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === EXTRACT T·ª™ CHUNK 121 ===\n",
                "START_CHUNK = 120\n",
                "START_PAGE = 17\n",
                "\n",
                "print(f\"üöÄ RESUME T·ª™ CHUNK {START_CHUNK + 1} (IMPROVED RELATIONS)\\n\")\n",
                "\n",
                "# Load PDF\n",
                "loader = PyPDFLoader(PDF_PATH)\n",
                "pages = loader.load()[START_PAGE-1:]\n",
                "print(f\"‚úÇÔ∏è C·∫Øt {START_PAGE-1} trang, c√≤n {len(pages)} trang\")\n",
                "\n",
                "# Split\n",
                "splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
                "chunks = splitter.split_documents(pages)\n",
                "print(f\"üì¶ T·ªïng: {len(chunks)} chunks\")\n",
                "print(f\"‚ñ∂Ô∏è  X·ª≠ l√Ω: chunk {START_CHUNK + 1} ‚Üí {len(chunks)}\\n\")\n",
                "\n",
                "# Extract\n",
                "extractor = ImprovedAMGExtractor(api_manager)\n",
                "chunks_to_process = chunks[START_CHUNK:]\n",
                "\n",
                "print(\"üß† ƒêANG TR√çCH XU·∫§T (Improved Relation Prompts)...\\n\")\n",
                "\n",
                "for i, chunk in enumerate(chunks_to_process, start=START_CHUNK+1):\n",
                "    page_num = chunk.metadata.get(\"page\", 0) + 1\n",
                "    result = extractor.extract(chunk.page_content)\n",
                "    \n",
                "    if result:\n",
                "        num_ent = len(result.entities)\n",
                "        num_rel = len(result.relations)\n",
                "        \n",
                "        if num_ent > 0:\n",
                "            avg_rel = sum(e.relevance_score for e in result.entities) / num_ent\n",
                "            print(f\"   [{i}/{len(chunks)}] +{num_ent} entities, +{num_rel} relations (avg: {avg_rel:.1f})\")\n",
                "            \n",
                "            for ent in result.entities:\n",
                "                add_entity(G, ent, page_num)\n",
                "            \n",
                "            for rel in result.relations:\n",
                "                add_relation(G, rel, page_num)\n",
                "        else:\n",
                "            print(f\"   [{i}/{len(chunks)}] --\")\n",
                "    else:\n",
                "        print(f\"   [{i}/{len(chunks)}] --\")\n",
                "    \n",
                "    # Save m·ªói 20 chunks\n",
                "    if i % 20 == 0:\n",
                "        with open(\"./amg_data/graph_improved.pkl\", \"wb\") as f:\n",
                "            pickle.dump(G, f)\n",
                "        print(f\"   üíæ Saved: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\\n\")\n",
                "    \n",
                "    time.sleep(1)\n",
                "\n",
                "print(f\"\\n‚úÖ XONG!\")\n",
                "print(f\"Final: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FREQUENCY BOOST ===\n",
                "print(\"\\nüìä FREQUENCY BOOST...\\n\")\n",
                "\n",
                "boosted = 0\n",
                "for node in list(G.nodes):\n",
                "    label = G.nodes[node].get('label', node)\n",
                "    pages = G.nodes[node].get('pages', [])\n",
                "    freq = len(pages)\n",
                "    \n",
                "    if freq >= 3:\n",
                "        boost = 0.1 if freq >= 5 else 0.05\n",
                "        old_conf = G.nodes[node]['confidence']\n",
                "        G.nodes[node]['confidence'] = min(1.0, old_conf + boost)\n",
                "        boosted += 1\n",
                "\n",
                "print(f\"‚úÖ Boosted {boosted} entities\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SAVE ===\n",
                "with open(\"./amg_data/graph_improved.pkl\", \"wb\") as f:\n",
                "    pickle.dump(G, f)\n",
                "\n",
                "print(f\"\\nüíæ ƒê√£ l∆∞u: graph_improved.pkl\")\n",
                "print(f\"   {G.number_of_nodes()} nodes | {G.number_of_edges()} edges\")\n",
                "print(f\"   T·ª∑ l·ªá: {G.number_of_edges()/G.number_of_nodes():.2f} edges/node\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VISUALIZE ===\n",
                "net = Network(height=\"850px\", width=\"100%\", directed=True, notebook=False)\n",
                "net.force_atlas_2based(gravity=-50, spring_length=200)\n",
                "\n",
                "color_map = {\n",
                "    'DISEASE': '#ff6b6b', 'DRUG': '#4ecdc4', 'SYMPTOM': '#ffe66d',\n",
                "    'TEST': '#95e1d3', 'TREATMENT': '#aa96da'\n",
                "}\n",
                "\n",
                "for node, data in G.nodes(data=True):\n",
                "    color = color_map.get(data.get('type', 'OTHER'), '#97C2FC')\n",
                "    conf = data.get('confidence', 0.5)\n",
                "    size = 15 + conf * 25\n",
                "    net.add_node(node, label=data.get('label'), color=color, size=size,\n",
                "                title=f\"{data.get('label')}<br>Conf: {conf:.2f}\")\n",
                "\n",
                "for u, v, data in G.edges(data=True):\n",
                "    width = 1 + data.get('confidence', 0.5) * 3\n",
                "    net.add_edge(u, v, label=data.get('relation'), width=width)\n",
                "\n",
                "net.show_buttons(filter_=['physics'])\n",
                "net.write_html(\"Medical_Graph_Improved_Relations.html\")\n",
                "\n",
                "print(\"‚úÖ Medical_Graph_Improved_Relations.html\")\n",
                "print(\"üéâ HO√ÄN T·∫§T!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}